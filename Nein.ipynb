{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nein",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/aYYvvMmkPNYlQWEGAE7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toshNaik/English-German/blob/master/Nein.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2t9SV86bLPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "c7df3bc3-9864-4ce5-f75c-bd109e8ccc81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxiR-pAIf1-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e16ae847-cd19-4f2f-fe2a-b36269523268"
      },
      "source": [
        "!unzip drive/My\\ Drive/english-german/deu-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/english-german/deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVSCEn4g2dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM, Input, Embedding, TimeDistributed\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7W5DddJC39x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "4ef90547-79fd-4faf-e8d1-c48934c4dbf7"
      },
      "source": [
        "file1 = open('deu.txt', 'r')\n",
        "dataset = []\n",
        "for line in file1.readlines():\n",
        "  dataset.append(line)\n",
        "file1.close()\n",
        "\n",
        "eng = []\n",
        "deu = []\n",
        "for line in dataset:\n",
        "  english, deutsche, _ = re.split('\\t', line)\n",
        "  english = re.sub(r'[^\\w\\s]', '', english)   #remove punctuation\n",
        "  deutsche = re.sub(r'[^\\w\\s]', '', deutsche)\n",
        "  english = re.sub(r'\\d', '', english)        #remove digits\n",
        "  deutsche = re.sub(r'\\d', '', deutsche)\n",
        "  eng.append(english.lower())\n",
        "  deu.append(deutsche.lower()+' <EOS>')\n",
        "\n",
        "eng_data = pd.Series(eng)\n",
        "deu_data = pd.Series(deu)\n",
        "deu_input_data = deu_data.copy().apply(lambda x: '<BOS>' + x)\n",
        "\n",
        "def tokenize(data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  return tokenizer\n",
        "\n",
        "english_tokenizer = tokenize(eng_data.values)\n",
        "english_vocab_size = len(english_tokenizer.word_index) + 1\n",
        "print(f'English vocab size {english_vocab_size}')\n",
        "\n",
        "german_tokenizer = tokenize(deu_input_data.values)\n",
        "german_vocab_size = len(german_tokenizer.word_index) + 1\n",
        "print(f'German vocab size {german_vocab_size}')\n",
        "\n",
        "eng_tokens = english_tokenizer.texts_to_sequences(eng_data.values)\n",
        "deu_tokens_output = german_tokenizer.texts_to_sequences(deu_data.values)\n",
        "deu_tokens_input = german_tokenizer.texts_to_sequences(deu_input_data.values)\n",
        "english_padded = pad_sequences(eng_tokens, padding='post')\n",
        "print(f'English padded: {english_padded.shape}')\n",
        "german_padded_input = pad_sequences(deu_tokens_input, padding='post')\n",
        "print(f'German input padded: {german_padded_input.shape}')\n",
        "german_padded_output = pad_sequences(deu_tokens_output, padding='post', maxlen = german_padded_input.shape[1])\n",
        "print(f'German output padded: {german_padded_output.shape}')\n",
        "\n",
        "german_padded_output = german_padded_output.reshape(german_padded_output.shape[0], german_padded_output.shape[1], 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.concatenate((english_padded, german_padded_input), axis =1), german_padded_output, test_size = 7000, shuffle=True, random_state=57)\n",
        "\n",
        "english_inputs = X_train[:, :101]\n",
        "print(english_inputs.shape)\n",
        "german_inputs = X_train[:, 101:]\n",
        "print(german_inputs.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "english_inputs_val = X_test[:, :101]\n",
        "print(english_inputs_val.shape)\n",
        "german_inputs_val = X_test[:, 101:]\n",
        "print(german_inputs_val.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English vocab size 16187\n",
            "German vocab size 34990\n",
            "English padded: (217032, 101)\n",
            "German input padded: (217032, 77)\n",
            "German output padded: (217032, 77)\n",
            "(210032, 101)\n",
            "(210032, 77)\n",
            "(210032, 77, 1)\n",
            "(7000, 101)\n",
            "(7000, 77)\n",
            "(7000, 77, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uccRESTmjgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_input = Input(shape=(None,))\n",
        "enc_emb = Embedding(english_vocab_size, 64)(enc_input)\n",
        "enc_lstm_layer = LSTM(64, return_state = True, name='encoder')\n",
        "_, state_h, state_c = enc_lstm_layer(enc_emb)\n",
        "enc_state = [state_h, state_c]\n",
        "\n",
        "dec_input = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(german_vocab_size, 64)\n",
        "dec_emb = dec_emb_layer(dec_input)\n",
        "dec_lstm_layer = LSTM(64, return_sequences=True, return_state = True, name='decoder')\n",
        "dec_out, _, _ = dec_lstm_layer(dec_emb, initial_state = enc_state)\n",
        "dec_softmax = TimeDistributed(Dense(german_vocab_size, activation='softmax'))\n",
        "dec_out = dec_softmax(dec_out)\n",
        "model = Model([enc_input, dec_input], dec_out)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlF3SZOea6XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import metrics\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[metrics.sparse_categorical_accuracy])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi3OVimiCQeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "798e90f2-2dbf-432b-fba8-88ec798e7bc8"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model.fit(x = [english_inputs, german_inputs], y = y_train,\n",
        "          batch_size=128, epochs=5,\n",
        "          validation_data=([english_inputs_val, german_inputs_val], y_test),\n",
        "          callbacks = [ModelCheckpoint('model.h5', monitor='val_loss', mode='min', save_best_only=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1641/1641 [==============================] - 1201s 732ms/step - loss: 0.2570 - sparse_categorical_accuracy: 0.9511 - val_loss: 0.3121 - val_sparse_categorical_accuracy: 0.9472\n",
            "Epoch 2/5\n",
            "1641/1641 [==============================] - 1192s 726ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9518 - val_loss: 0.3079 - val_sparse_categorical_accuracy: 0.9477\n",
            "Epoch 3/5\n",
            "1641/1641 [==============================] - 1203s 733ms/step - loss: 0.2452 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.3044 - val_sparse_categorical_accuracy: 0.9482\n",
            "Epoch 4/5\n",
            "1641/1641 [==============================] - 1210s 737ms/step - loss: 0.2395 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.3017 - val_sparse_categorical_accuracy: 0.9486\n",
            "Epoch 5/5\n",
            " 832/1641 [==============>...............] - ETA: 9:48 - loss: 0.2328 - sparse_categorical_accuracy: 0.9543"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9mnUgGmEbPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder inference model\n",
        "enc_model = Model(enc_input, enc_state)\n",
        "\n",
        "# Decoder inference model\n",
        "state_h_in = Input(shape = (64,))\n",
        "state_c_in = Input(shape = (64,))\n",
        "dec_state_in = [state_h_in, state_c_in]\n",
        "dec_emb_pred = dec_emb_layer(dec_input)\n",
        "dec_out_pred, state_h_out, state_c_out = dec_lstm_layer(dec_emb_pred, initial_state = dec_state_in)\n",
        "\n",
        "dec_out_pred = dec_softmax(dec_out_pred)\n",
        "dec_model = Model([dec_input] + dec_state_in, [dec_out_pred, state_h_out, state_c_out])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_V2ftMUgdXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_german(sentence):\n",
        "  eng_pred = pad_sequences(english_tokenizer.texts_to_sequences([sentence]), maxlen=101, padding='post')\n",
        "  dec_init = enc_model.predict(eng_pred)\n",
        "  dec_word = np.array([[1]]) # token for <BOS>\n",
        "\n",
        "  stop = False\n",
        "  deu_sentence = ''\n",
        "  while not stop:\n",
        "    output = dec_model.predict([dec_word] + dec_init)\n",
        "    output_seq = output[0]\n",
        "    new_states = output[1:]\n",
        "    \n",
        "    new_id = np.argmax(output_seq[0, -1, :])\n",
        "    new_word = german_tokenizer.index_word[new_id]\n",
        "\n",
        "    if (new_word == 'eos' or len(deu_sentence.split()) == 77):\n",
        "      stop = True\n",
        "    else:\n",
        "      deu_sentence += new_word + ' '\n",
        "\n",
        "    dec_word = np.array([[new_id]])\n",
        "    dec_init = new_states\n",
        "  return deu_sentence"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmLW13pEtCse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "f5d2b319-ef63-4fbf-d6e3-fe8870e4da2c"
      },
      "source": [
        "print(f\"English: How are you         ||| German : {predict_german('How are you'.lower())}\")\n",
        "print(f\"English: What is your name   ||| German : {predict_german('What is your name'.lower())}\")\n",
        "print(f\"English: Are you hungry      ||| German : {predict_german('Are you hungry'.lower())}\")\n",
        "print(f\"English: My name is Ashutosh ||| German : {predict_german('My name is Ashutosh'.lower())}\")\n",
        "print(f\"English: It is a dog         ||| German : {predict_german('It is a dog'.lower())}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English: How are you         ||| German : wie bist du \n",
            "English: What is your name   ||| German : wie heißt du \n",
            "English: Are you hungry      ||| German : hast du hunger \n",
            "English: My name is Ashutosh ||| German : mein name ist \n",
            "English: It is a dog         ||| German : es ist eine katze \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwdb_IaLkBFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To save a model\n",
        "loaded.save('/content/drive/My Drive/english-german/latest5.hdf5')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5BrIVmbLKps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a model from drive\n",
        "loaded = load_model('/content/drive/My Drive/english-german/latest6.4.hdf5')\n",
        "\n",
        "# Get layers from loaded model\n",
        "enc_input = loaded.input[0]\n",
        "enc_emb = loaded.get_layer(name = 'embedding_2').output\n",
        "_, state_h, state_c = loaded.get_layer(name = 'encoder').output\n",
        "enc_state = [state_h, state_c]\n",
        "\n",
        "dec_input = loaded.input[1]\n",
        "dec_emb_layer = loaded.get_layer(name='embedding_3').output\n",
        "dec_lstm_layer = loaded.get_layer(name='decoder')\n",
        "dec_softmax = loaded.get_layer(name='time_distributed_1')\n",
        "\n",
        "# Encoder inference model\n",
        "enc_model = Model(enc_input, enc_state)\n",
        "\n",
        "# Decoder inference model\n",
        "state_h_in = Input(shape = (64,))\n",
        "state_c_in = Input(shape = (64,))\n",
        "dec_state_in = [state_h_in, state_c_in]\n",
        "\n",
        "dec_out_pred, state_h_out, state_c_out = dec_lstm_layer(dec_emb_layer, initial_state = dec_state_in)\n",
        "\n",
        "dec_out_pred = dec_softmax(dec_out_pred)\n",
        "dec_model = Model([dec_input] + dec_state_in, [dec_out_pred, state_h_out, state_c_out])"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}